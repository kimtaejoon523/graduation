{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# #CSV 파일에 헤더를 추가\n",
    "with open('test.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['r','g','b', 'Mouth Openness','mouth_width', 'Label'])\n",
    "\n",
    "\n",
    "# Mediapipe의 Face Mesh 모델 로드\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh()\n",
    "\n",
    "# 웹캠에서 영상을 받아오는 VideoCapture 객체 생성\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "start_time = datetime.now()\n",
    "elapsed_time = timedelta(seconds=0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"비디오 캡처 실패, 종료합니다.\")\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # 프레임을 BGR에서 RGB로 변환\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # 얼굴 검출 및 랜드마크 추출\n",
    "    results = face_mesh.process(rgb_frame)\n",
    "\n",
    "    \n",
    "    if results.multi_face_landmarks:\n",
    "     \n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "\n",
    "            mouth_area=frame.copy()\n",
    "\n",
    "            landmark_indices =[0,61, 146, 91, 181, 84, 17, 314, 405, 321, 375, 291,37,39,40,267,269,270]\n",
    "         \n",
    "\n",
    "\n",
    "            landmarks=[face_landmarks.landmark[i]for i in landmark_indices]\n",
    "          \n",
    "            \n",
    "         \n",
    "            h, w, _ = frame.shape\n",
    "            x_1 = int(np.mean([landmark.x * w for landmark in landmarks]))\n",
    "            y_1 = int(np.mean([landmark.y * h for landmark in landmarks]))-5\n",
    "\n",
    "\n",
    "            cv2.circle(frame, (x_1, y_1),2, (0, 255, 0), -1)\n",
    "            \n",
    "            \n",
    "        \n",
    "\n",
    "            for idx in landmark_indices:\n",
    "                landmark = face_landmarks.landmark[idx]\n",
    "                x = int(landmark.x * frame.shape[1])\n",
    "                y = int(landmark.y * frame.shape[0])\n",
    "                cv2.circle(frame,(x,y),3,(255,0,0),-1)\n",
    "            \n",
    "\n",
    "            # rgb값과 brightness값\n",
    "            mask = np.zeros(gray_frame.shape, dtype=np.uint8)\n",
    "            points = np.array([[int(landmark.x * w), int(landmark.y * h)] for landmark in landmarks], dtype=np.int32)\n",
    "            cv2.fillPoly(mask, [points], 255)\n",
    "\n",
    "            brightness = cv2.mean(gray_frame, mask=mask)[0]\n",
    "            # print(brightness)\n",
    "  \n",
    "          \n",
    "\n",
    "\n",
    "            if y_1 < h and x_1 < w:\n",
    "                rgb_value = rgb_frame[y_1, x_1]\n",
    "                r, g, b = rgb_value[0], rgb_value[1], rgb_value[2]\n",
    "                r=round(r/brightness,4)\n",
    "                g=round(g/brightness,4)\n",
    "                b=round(b/brightness,4)\n",
    "\n",
    "            else:\n",
    "                print(f\"Invalid coordinates: face not detected\")\n",
    "\n",
    "           \n",
    "                   \n",
    "            #웹캠과의 거리에 따라 입의 가로길이와 세로길이가 변경함에 따라 기준값으로 얼굴너비를 설정\n",
    "\n",
    "            face_width = math.sqrt(\n",
    "            (face_landmarks.landmark[172].x - face_landmarks.landmark[264].x) ** 2 +\n",
    "            (face_landmarks.landmark[172].y - face_landmarks.landmark[264].y) ** 2\n",
    "        )\n",
    "            face_width=20*face_width\n",
    "        \n",
    "\n",
    "            #입의 세로길이=>고중저모음 판단기준\n",
    "\n",
    "            upper_lip_bottom = (face_landmarks.landmark[12].x, face_landmarks.landmark[12].y)\n",
    "            lower_lip_top = (face_landmarks.landmark[14].x, face_landmarks.landmark[14].y)\n",
    "            mouth_openness = (lower_lip_top[1] - upper_lip_bottom[1])/face_width\n",
    "            mouth_openness=round(100*mouth_openness,4)\n",
    "\n",
    "        \n",
    "            # 입의 가로길이를 계산=>원순/평순 판단기준\n",
    "            \n",
    "            lip_left =(face_landmarks.landmark[61].x, face_landmarks.landmark[61].y)\n",
    "            lip_right=(face_landmarks.landmark[291].x, face_landmarks.landmark[291].y)\n",
    "            mouth_width=(lip_right[0]-lip_left[0])/face_width\n",
    "            mouth_width=round(10*mouth_width,4)\n",
    "\n",
    "          \n",
    "            # 경과 시간이 0.2초 이상일 때만 CSV 파일에 추가\n",
    "            if elapsed_time.total_seconds() >= 0.2:\n",
    "                # 시간 단위로 입안 명암도, 입 벌림 정도, 입의 가로길이를 CSV 파일에 추가\n",
    "\n",
    "                with open('test.csv', mode='a', newline='') as file:\n",
    "                    writer = csv.writer(file)\n",
    "                    writer.writerow([r,g,b,mouth_openness,mouth_width,]) \n",
    "                    \n",
    "\n",
    "                # 경과 시간 초기화\n",
    "                elapsed_time = timedelta(seconds=0)\n",
    "            else:\n",
    "                # 경과 시간 누적\n",
    "                elapsed_time += datetime.now() - start_time\n",
    "                start_time = datetime.now()\n",
    "            \n",
    "\n",
    "            # 입 벌림 정도, 입안 명암도, 입의 가로길이를 프레임에 표시\n",
    "           \n",
    "            cv2.putText(frame, f\"Mouth Openness: {mouth_openness:.4f}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "            cv2.putText(frame, f\"Mouth Width: {mouth_width:.4f}\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "            cv2.putText(frame, f\"RGB: ({r:},{g:},{b:})\", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "       \n",
    "            \n",
    "    # 영상 출력\n",
    "    cv2.imshow('Face Mesh', frame)\n",
    "    \n",
    "    # 종료 키 (q) 입력 시 종료\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break \n",
    "\n",
    "\n",
    "# 자원 해제\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step\n",
      "새로운 데이터 1의 예측 클래스: 6\n",
      "새로운 데이터 2의 예측 클래스: 3\n",
      "새로운 데이터 3의 예측 클래스: 6\n",
      "새로운 데이터 4의 예측 클래스: 6\n",
      "새로운 데이터 5의 예측 클래스: 4\n",
      "새로운 데이터 6의 예측 클래스: 3\n",
      "새로운 데이터 7의 예측 클래스: 4\n",
      "새로운 데이터 8의 예측 클래스: 3\n",
      "새로운 데이터 9의 예측 클래스: 3\n",
      "새로운 데이터 10의 예측 클래스: 3\n",
      "새로운 데이터 11의 예측 클래스: 3\n",
      "새로운 데이터 12의 예측 클래스: 3\n",
      "새로운 데이터 13의 예측 클래스: 3\n",
      "새로운 데이터 14의 예측 클래스: 3\n",
      "새로운 데이터 15의 예측 클래스: 3\n",
      "예측 클래스들의 최빈값: 3\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import firebase_admin\n",
    "from firebase_admin import credentials, db\n",
    "\n",
    "# 모델과 스케일러 로드\n",
    "model1 = tf.keras.models.load_model('722.keras')\n",
    "scaler1 = joblib.load('scaler2.joblib')\n",
    "\n",
    "\n",
    "# 새로운 데이터 로드 및 전처리\n",
    "new_data = pd.read_csv('test.csv')\n",
    "new_data = np.array(new_data)\n",
    "scaled_data = scaler1.transform(new_data[:,:5]) # transform만 수행\n",
    "\n",
    "# 예측 수행\n",
    "predictions = model1.predict(scaled_data)\n",
    "\n",
    "# 예측 결과 출력\n",
    "predicted_classes = []\n",
    "for i, prediction in enumerate(predictions):\n",
    "    predicted_class = np.argmax(prediction)\n",
    "    print(f\"새로운 데이터 {i+1}의 예측 클래스: {predicted_class}\")\n",
    "    predicted_classes.append(predicted_class)\n",
    "\n",
    "most_common_class = Counter(predicted_classes).most_common(1)[0][0]\n",
    "print(f\"예측 클래스들의 최빈값: {most_common_class}\")\n",
    "\n",
    "# Firebase 초기화\n",
    "# cred = credentials.Certificate(\"firebasepy.json\")\n",
    "# firebase_admin.initialize_app(cred, {\n",
    "#     'databaseURL': 'https://anproject-846d0-default-rtdb.firebaseio.com/'\n",
    "# })\n",
    "\n",
    "def get_next_path(base_path):\n",
    "    ref = db.reference(base_path)\n",
    "    snapshot = ref.get()\n",
    "    if isinstance(snapshot, dict):\n",
    "        keys = list(snapshot.keys())\n",
    "        next_index = len(keys) + 1\n",
    "    elif isinstance(snapshot, list):\n",
    "        next_index = len(snapshot)\n",
    "    else:\n",
    "        next_index = 1\n",
    "    return f\"{base_path}/{next_index}\"\n",
    "\n",
    "# 데이터 업로드\n",
    "base_path = 'devices/Result'\n",
    "next_path = get_next_path(base_path)\n",
    "common_ref = db.reference(next_path)\n",
    "common_ref.set({'vowel': int(most_common_class)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
